\section{Experimental Results}
\label{sec:expt}
This section discusses our experimental setup and provides performance evaluation of the proposed framework. We conduct our experiments on YouTube videos using the YouTube API. We have used Wikipedia Thesaurus API \cite{nakayama2007wikipedia} and Reverse Dictionary \cite{ReverseDictionary} as the sources of candidate keywords given the name of a category. The candidates for a category are made distinct by removing any repetitions. The classifier used is a linear Support Vector Machine (SVM). Performance is compared against baseline classifier, which is a linear SVM trained over videos retrieved by category names. Classification accuracy is taken to be the performance measure. Textual data for a video is obtained from the Title, Keywords, and Description in the corresponding webpage. Each video webpage is represented as a bag of word vector of normalized word counts. Textual vocabulary is created based on collecting unigrams that occur in more than 0.5\% of total video webpages in training data, and by removing stop words (such as \textit{it, a, or, was} etc). \\
\indent      We conducted a user study to obtain videos viewed by a set of volunteers. More than 14000 videos viewed by 30 volunteers were collected. The testing videos for our proposed framework are obtained by manually labeling videos collected by the above user study. Testing videos for a category are also supplemented by videos from publicly available lists of popular (or useful or best) videos of the category.  \\
\indent      In the next three sub-sections, we summarize results of applying our proposed approach on three different sets of categories.
\input{TrainingData/ExptFigures.tex}
\begin{table}
\fontsize{8pt}{1em}\selectfont
\begin{center}
\caption{{Summary of average classification accuracy obtained using Adapt AAO approach}
\label{tab:SumAAOResults}}
\begin{tabular}{|p{0.25\linewidth}|p{0.20\linewidth}|p{0.20\linewidth}|p{0.20\linewidth}|}
		\hline
		\textbf{Approach to select L SRKs} & \textbf{Retail Product categories: Baby, Clothing, Fitness, Food} & \textbf{Genres of Music: Classical, Electronic, Jazz, Rock} & \textbf{Genres of Movies: Action, Comedy, Horror, Romantic} \\
		\hline
		Maximize average Proximity  & 91\%  & 91\% & 58.3\%  \\
		\hline
		Maximize diversity & 79.4\% & 89.7\%  &  48\%  \\
		\hline
		Based on Algorithm V & 92.6\%  & 92.4\% & 61.4\%  \\
		\hline
\end{tabular}
\end{center}
\end{table}

\subsection{Retail Product categories: Baby, Clothing, Fitness, Food }
%\vspace{-2mm}
     As discussed earlier, for a retail or department store (such as Walmart or Sears), knowledge of user preferences in product categories like the above is very useful. We first discuss results obtained using the baseline classifier followed by results obtained using the proposed approaches. 

Fig.~\ref{fig:searsCategoryName} shows the performance of the baseline classifier for classifying 255 test videos. It is seen that the performance of the baseline classifier improves initially as more videos are retrieved by category name and used for training. As shown in Fig.~\ref{fig:searsCategoryName}, the average (across all categories) Intra-Category Diversity (\ref{eq:diversityeqn}) of the training data thus obtained, increases with the number of retrieved videos, initially leading to performance improvement. However, as more videos are retrieved using the category name, the quality of retrieved videos by the video search engine begins degrading, and more training videos unrelated to the respective categories are retrieved and selected in their training data. This is reflected in loss in classification performance (around 700-800 videos per category) as more videos are retrieved using category name. In our experiments, 1000 videos are retrieved per SRK. In order to provide a fair comparison of our approach with the baseline, the number of training videos in both cases should be equal. However, from the trend in Fig.~\ref{fig:searsCategoryName} it can be seen that the best baseline performance is around 82.3\%. Since the YouTube API limits number of retrieved videos per keyword to 1000, we utilize the best classification performance (82.3\%) of baseline to compare with our techniques.  

In Fig.~\ref{fig:searsalpha}, we present performance variation of the proposed approaches with the moderation factor $\alpha$. Keywords from \cite{nakayama2007wikipedia} and top 200 keywords from \cite{ReverseDictionary}  are used as candidates, giving a total of 230 candidates per category. The number of valid keywords found per category are Baby: 81, Clothing: 63, Fitness: 78, Food: 52. The coefficients $N_1$ and $N_2$ in (\ref{eq:SRTeq}) are chosen such that $N_1$=$\frac{1}{N_2}$=$div(RV(C_i))$. Fig.~\ref{fig:searsalpha} shows the performance when $L$' number of SRKs are selected per category, where $L$' is the minimum number of valid keywords across all categories (which is 52 in this case). We show the performance using both Weighted Instances and Non-weighted Instances methods for LCPD. Weighted support vector machine \cite{yang2007weighted} is used to give varying weights to the training videos as per the Weighted Instances method. Fig.~\ref{fig:searsalpha} also shows the performance obtained by the Adapt AAO approach. As mentioned earlier, the performance of the Adapt AAO approach is same as that of the AAO approach with a small $\Delta$, and so we have only provided performance results of the former. For LCPD, $\alpha$ = 0.6 to 1 performs best for Non-weighted Instances method, and $\alpha$ = 0.6 to 0.8 performs best for Weighted Instances method. We observe that the Weighted Instances method in general performs better than the Non-weighted Instances method, as discussed in Section~\ref{sec:lcpd}. Moreover, both the methods have significantly better accuracy than the baseline classifier accuracy of 82.3\% (shown by the dotted line in Fig.~\ref{fig:searsalpha}). For the baseline case, the Intra-Category Diversity values (\ref{eq:diversityeqn}) of the training data are  \{\textit{0.259, 0.247, 0.244, 0.243}\} corresponding to \{\textit{Baby, Clothing, Fitness, Food}\}. Compared to this, the Intra-Category Diversity after all 52 SRKs (for $\alpha$ = 0.6) are used to retrieve training videos for above categories are \{\textit{0.439, 0.418, 0.395, 0.359}\}. The average (taken across all categories) Intra-Category Diversity has increased from $0.248$ for baseline to $0.403$ with LCPD (for 52 SRKs per category, and $\alpha$ = 0.6). Consequently, the classifier performance has also increased from 82.3\% (baseline performance) to $91$\% (Non-Weighted Instances) and $93.7$\% (Weighted Instances), thus demonstrating that higher Intra-Category Diversity in training videos results in better performance of the trained classification model. The classification accuracy obtained using Adapt AAO is 92.6\%. Based on Fig.~\ref{fig:searsalpha} it can also be seen that unlike LCPD, the performance of Adapt AAO does not depend on $\alpha$. While the performance of Adapt AAO is lower than the best performance of LCPD, the difference is marginal. In addition, the performance of Adapt AAO is significantly higher than the baseline performance. 

Fig.~\ref{fig:searsNumkeywords} shows how the performance of the proposed approaches varies with respect to $L$, i.e., the number of SRKs. For LCPD, $\alpha$ is kept constant at $0.6$ for this experiment. As can be seen for LCPD approach, while the performance of the Non-Weighted Instances method starts decreasing after initially increasing with increasing $L$, the Weighted Instances method performs better, and continues its improving performance with increasing $L$. The Adapt AAO approach is seen to consistently provide high classification accuracy. In addition, Adapt AAO offers the advantage of not requiring tuning of the parameter $\alpha$ which may require human effort or the availability of a labeled validation set. Table~\ref{tab:SumAAOResults} shows the accuracy obtained as per the proposed Adapt AAO approach as well as the accuracy obtained when all SRKs are selected to maximize only one objective function as discussed in Section~\ref{sec:aao}. It can be seen that the performance of our approach outperforms selecting SRKs based on only one objective function, namely average proximity (\ref{eq:proximityscore}) or diversity (\ref{eq:divaao}). 

Fig.~\ref{fig:searsTime} shows the time taken by the LCPD and Adapt AAO approaches with respect to the number of SRKs selected (i.e., $L$). Conforming to the complexity discussion in Section~\ref{sec:selectionSRK}, the time taken to select $L$ SRKs varies as $O(L)$ when the number of candidates and the categories are fixed. Fig.~\ref{fig:searsTime} also shows the time taken by a linear SVM (LibLinear implementation of SVM) to train over the collected set of training videos. The time-taken to learn the classifier varies approximately as $O(L)$. 

For our MATLAB-based implementation, the system memory usage for LCPD approach was 4.46 GBs for selecting 52 SRKs from 230 candidate keywords for category $Baby$. Since the Adapt AAO approach does not need to store the representations of individual retrieved videos retrieved per keyword, like in LCPD approach, the memory requirement for Adapt AAO approach is only 411 MBs. Training of SVM using 1000 videos for each of 52 SRKs required 1.4GBs. The empirical results presented demonstrate the feasibility of our proposed approach in terms of space and time complexities. 

We next present experimental results for two more sets of categories and focus on the classifier performance. 

\subsection{Genres of Music: Classical, Electronic, Jazz, Rock}
We have chosen these categories keeping the requirements of a music recommendation system in mind. While there are several, and often subjective, categorizations possible within Music, we have chosen the above four categories since these cover most other categories, and are broad in the sense of ease of labeling by a human expert. Top 100 keywords from \cite{ReverseDictionary}   are used to obtain candidates for each category. 26 SRKs are selected per category. 290 test videos are used to test the performance of the baseline classifier and the proposed approaches. In Fig.~\ref{fig:musicGenrealpha}, we present performance of the proposed approaches. While the performance of LCPD varies with $\alpha$, it is seen that performance of classifier for $\alpha \ge$ 0.2 is almost the same. The Weighted Instances method is again seen to outperform the Non-Weighted Instances method for higher $\alpha$ values ($\alpha \ge$0.2), and both show significantly better accuracy (92.4\% and 91\% respectively) than the baseline classifier (77.9\%). For these categories, Adapt AAO provides as high classification accuracy (92.4\%) as LCPD when 26 SRKs are used. This demonstrates the efficacy of the Adapt AAO approach to achieve high performance without the requirement of $\alpha$. 

\subsection{Genres of Movies: Action, Comedy, Horror, Romantic}
We here provide results for a set of categories that might be of interest for a movie recommendation system. \cite{ReverseDictionary} is used to obtain Candidate Keyword for each category. A total of 223 test videos are used to assess performance. 18 SRKs are selected per category. Fig.~\ref{fig:movieGenrealpha} supports the observation made with the previous sets of categories. For LCPD, the Weighted Instances is seen to be better performing than Non-Weighted Instances and both methods show significantly improved performance (62.8\% and 59.6\% respectively) compared to performance of baseline classifier (41.2\%).  Adapt AAO leads to marginally worse performance than LCPD and achieves 61.4\% classification accuracy. Both LCPD and AAO approaches achieve significant improvements in predictive correctness as compared to the baseline approach. 

Based on the above experiments, it can be seen that the proposed approaches LCPD and Adapt AAO, both lead to significant improvement in classification performance compared to the baseline classifier. The performance of Adapt AAO is slightly worse than LCPD, however since the former does not depend on $\alpha$, Adapt AAO offers a convenient approach to obtain high classification accuracy without necessitating manually provided preferences for objective functions or requiring manual effort to label validation videos and tune $\alpha$. 

%\vspace{-0.15in}
