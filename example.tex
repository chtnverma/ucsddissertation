\documentclass[12pt]{ucsddissertation}
% mathptmx is a Times Roman look-alike (don't use the times package)
% It isn't clear if Times is required. The OGS manual lists several
% "standard fonts" but never says they need to be used.
\usepackage{mathptmx}
\usepackage[NoDate]{currvita}
\usepackage{array}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{ragged2e}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{algorithm}% http://ctan.org/pkg/algorithms
\usepackage{amsmath} 
\usepackage{amsthm,amssymb}
%\usepackage[subfigure]{tocloft} 
%\usepackage{subfigure} 
\usepackage{color,caption}
\usepackage[hyphens]{url}
\usepackage[breaklinks=true,pdfborder={0 0 0}]{hyperref}
\usepackage{epsfig} 
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\hilight}[1]{\colorbox{yellow}{#1}}

%% Yahoo -- begin
\newtheorem{definition}{Definition}
\usepackage[mathscr]{euscript}
\usepackage{float}
\usepackage{mathrsfs}
\usepackage{subcaption}
%\usepackage{epstopdf}
\usepackage{soul}
\usepackage{caption}
\renewcommand{\hl}{}
%% Yahoo -- end 


%% Symantec -- begin 
%\usepackage{algorithmic}
\usepackage{xcolor}
\usepackage{url}
\usepackage{pifont}
\usepackage{tabto}
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\codecomment}{\textbackslash \textbackslash}
\DeclareGraphicsExtensions{.eps,.pdf,.png,.jpg}

%% Symantec -- end

\AtBeginDocument{%
	\settowidth\cvlabelwidth{\cvlabelfont 0000--0000}%
}

% OGS recommends increasing the margins slightly.
\increasemargins{.1in}

% These are just for testing/examples, delete them
\usepackage{trace}
%\usepackage{showframe} % This package was just to see page margins
\usepackage[english]{babel}
\newcommand{\comment}[1]{}
\usepackage{blindtext}
\overfullrule5pt
% ---

% Required information
\title{Enabling Automated and Efficient Personalization Systems}
\author{Chetan Kumar Verma}
\degree{Electrical and Computer Engineering (Computer Engineering)}{Doctor of Philosophy}
% Each member of the committee should be listed as Professor Foo Bar.
% If Professor is not the correct title for one, then titles should be
% omitted entirely.
\chair{Professor Sujit Dey}
% Your committee members (other than the chairs) must be in alphabetical order
\committee{Professor David Kriegman}
\committee{Professor Lawrence Saul}
\committee{Professor Truong Nguyen}
\committee{Professor Vikash Gilja}
\degreeyear{2015}

% Start the document
\begin{document}
% Begin with frontmatter and so forth
\frontmatter
\maketitle
\makecopyright
\makesignature
% Optional
\begin{dedication}
\setsinglespacing
\raggedright % It would be better to use \RaggedRight from ragged2e
\parindent0pt\parskip\baselineskip
\centering
To mom and dad 
\end{dedication}
% Optional
\comment{
\begin{epigraph}
\vskip0pt plus.5fil
\setsinglespacing
{\flushright
True ease in writing comes from art, not chance,\\
As those move easiest who have learn'd to dance.\\
'T is not enough to no harshness gives offence,---\\
The sound must seem an echo to the sense.

\vskip\baselineskip
\textit{Alexander Pope}\par}
\vfil
\begin{center}
You write with ease to show your breeding,\\
But easy writing's curst hard reading.

\vskip\baselineskip
\textit{Richard Brinsley Sheridan}
\end{center}
\vfil
\noindent Writing, at its best, is a lonely life. Organizations for
writers palliate the writer's loneliness, but I doubt if they improve
his writing. He grows in public stature as he sheds his loneliness and
often his work deteriorates. For he does his work alone and if he is a
good enough writer he must face eternity, or the lack of it, each day.

\vskip\baselineskip
\hskip0pt plus1fil\textit{Ernest Hemingway}\hskip0pt plus4fil\null

\vfil
\end{epigraph}
}

% Next comes the table of contents, list of figures, list of tables,
% etc. If you have code listings, you can use \listoflistings (or
% \lstlistoflistings) to have it be produced here as well. Same with
% \listofalgorithms.
\tableofcontents
\listoffigures
\listoftables

% Preface
\comment{
\begin{preface}
Almost nothing is said in the manual about the preface. There is no
indication about how it is to be typeset. Given that, one is forced to
simply typeset it and hope it is accepted. It is, however, optional
and may be omitted.
\end{preface}
}

% Your fancy acks here. Keep in mind you need to ack each paper you
% use. See the examples here. In addition, each chapter ack needs to
% be repeated at the end of the relevant chapter.
\begin{acknowledgements}


This dissertation would not have been possible without the help and support of my family, friends, colleagues and mentors. I would like to take this opportunity to thank them. 


First, I would like to thank Prof. Sujit Dey for patience to train me to think and write with clarity. This has helped me not only in my research and technical writing, but also in other aspects of my life. 

My parents have been the cornerstone of my education and career through their unconditional and selfless support. I would like to thank them for being extremely patient even though they didnâ€™t always understand my opinions and decisions. This achievement is as much mine as it is theirs. 

I would also like to thank Sandeep Bhatkar, Michael Hart, Vijay Mahadevan, Nikhil Rasiwasia, Gaurav Aggarwal for mentoring me during internships. My internships have facilitated a good chunk of my learning and the contribution of my mentors has been significant. I would like to thank Nitesh Shroff for doubling up as a friend and mentor when I needed the help. 

Graduate school has been a fun and learning experience for me. I would like to thank my friends Kritika, Bharathan, Rishi, Manish, Ravee, Sumit, and many others for making the journey enjoyable. It would have been much less exciting if I did not have them to pour my heart out. My labmates especially Yao, Jason, Po-Han, Ranjini, Ali have also been helpful to me to keep my sanity over the past years.  


Chapter 2, in part, contains material as it appears in IEEE Access. ``Methods to Obtain Training Videos for Fully Automated Application-Specific Classification''. Chetan Verma, Sujit Dey. The dissertation author was the primary investigator and author of this paper. 

Chapter 3, in part, contains material as it appears in Elsevier Expert Systems with Applications. ``Construction and Evaluation of Ontological Tag Trees''. Chetan Verma, Vijay Mahadevan, Nikhil Rasiwasia, Gaurav Aggarwal, Ravi Kant, Alejandro Jaimes, Sujit Dey. The dissertation author was the primary investigator and author of this paper. 

Chapter 4, in part, contains material as it has been accepted for publication for the IEEE Access. ``Improving Scalability of Personalized Recommendation Systems for Enterprise Knowledge Workers''. Chetan Verma, Sandeep Bhatkar, Michael Hart, Aleatha Parker-Wood, Sujit Dey. The dissertation author was the primary investigator and author of this paper. 

\end{acknowledgements}

% Stupid vita goes next
\begin{vita}
\noindent
\begin{cv}{}
\begin{cvlist}{}
\item[2008] Bachelor of Technology, \\Electrical Enginering, \\Indian Institute of Technology, Madras 
\item[2011] Master of Science, \\Electrical and Computer Engineering(Computer Engineering), \\University of California, San Diego 
\item[2010--2015] Graduate Student Researcher, \\Mobile Systems Design Lab, \\Department of Electrical and Computer Engineering, \\University of California, San Diego
\item[2011--2015]  Doctor of Philosophy, \\Department of Electrical and Computer Engineering, \\University of California, San Diego
\end{cvlist}
\end{cv}

% This puts in the PUBLICATIONS header. Note that it appears inside
% the vita environment. It is optional.
\publications
{\justify
\noindent\textbf{Journals} \\ \\
\noindent \textbf{C. Verma}, S. Dey, ``Methods to Obtain Training Videos for Fully Automated Application-Specific Classification'', IEEE Access, vol. 3, pp 1188-1205, 2015. \\

\noindent \textbf{C. Verma}, V. Mahadevan, N. Rasiwasia, G. Aggarwal, R. Kant, A. Jaimes, S. Dey, ``Construction and Evaluation of Ontological Tag Trees'', Elsevier Expert Systems and Applications, vol. 42 (24), pp 9587-9602, 2015. \\

\noindent \textbf{C. Verma}, M. Hart, S. Bhatkar, A. Parker-Wood, S. Dey, ``Improving Scalability of Personalized Recommendation Systems for Enterprise Knowledge Workers'', Under review. \\

\noindent \textbf{C. Verma}, B. R. Tamma, B. S. Manoj, R. Rao, ``A Realistic Small-World Model for Wireless Mesh Networks'', IEEE Communication Letters, vol. 15 (4), pp 455-457, 2011. \\

\noindent\textbf{Conferences} \\ \\
\noindent \textbf{C. Verma}, M. Hart, S. Bhatkar, A. Parker-Wood, S. Dey, ``Access Prediction for Knowledge Workers in Enterprise Data Repositories'', International Conference on Enterprise Information Systems (ICEIS), 2015. [\textbf{Nominated for best student paper award}] \\

\noindent B. Balaji, \textbf{C. Verma}, B. Narayanaswamy, Y. Agarwal, ``Zodiac: Organizing Large Deployment of Sensors to Create Reusable Applications for HVAC Management'', ACM International Conference on Embedded Systems For Energy-Efficient Built Environments (BuildSys), 2015. \\

\noindent \textbf{C. Verma}, V. Mahadevan, N. Rasiwasia, G. Aggarwal, R. Kant, A. Jaimes, S. Dey, ``Construction of Tag Ontological Graphs by Locally Minimizing Weighted Average Hops'', ACM World Wide Web (WWW poster), 2014. \\ 


\noindent \textbf{C. Verma}, S. Dey, ``Fully Automated Learning for Application-Specific Web Video Classification'', IEEE/WIC/ACM International Conference on Web Intelligence (WI), 2013. \\ 

\noindent A. Verma, \textbf{C. Verma}, B. R. Tamma, B. S. Manoj, R. Rao, ``New Link Addition Strategies for Multi-Gateway Small World Wireless Mesh Networks'', IEEE Advanced Networks and  Telecommunication Systems (ANTS), 2010. 

}

\comment{

% This puts in the FIELDS OF STUDY. Also inside vita and also
% optional.
\fieldsofstudy
\noindent Major Field: Engineering (Specialization or Focused Studies)
\vskip\baselineskip
Studies in Applied Mathematics\par
Professors Alpha Beta and Gamma Delta
\vskip\baselineskip
Studies in Mechanices\par
Professors Epsilon Zeta and Eta Theta
\vskip\baselineskip
Studies in Electromagnetism\par
Professors Iota Kappa and Lambda Mu

}
\end{vita}

% Put your maximum 350 word abstract here.
\begin{dissertationabstract}


Information explosion and the increasing use of Internet have fueled the growing popularity of personalization systems. Such systems can understand user interests to customize the information served to them, thereby addressing information overload. At the same time, personalization systems can also enable service and content providers to serve targeted advertisements and recommendations to users. In order to operate on the massive scales of the number of users and the amount of data available, personalization systems have a crucial requirement for automation and efficiency. In this dissertation, we identify key challenges faced by personalization systems and provide solutions to address them such that the above requirements can be achieved. 

We first note that content classification is an important component of personalization systems. Approaches to train classification models typically depend on manual collection and labeling of training data, which makes the entire process non-scalable. To address this, we develop a completely automated framework that can provide labeled training data for arbitrary set of categories. Experiments using online videos demonstrate the feasibility and effectiveness of our approach. 


The second key challenge we address is the sparsity in annotations of popular online content such as Flickr images. Sparse or missing tags hamper the ability of personalization systems to recommend content or to infer the interests of users that access them. To address this, we show how ontological tag trees can be constructed from corpus based statistics and semantic relationships between tags, to alleviate tag sparsity in a space efficient manner. Through evaluations, we demonstrate the effectiveness and efficiency of ontological tag trees as compared to existing methods. 


Lastly, we focus on alleviating information overload in enterprise repositories. We design a file metadata based recommendation system that captures per user access patterns and user collaboration to recommend new files. In order to address scalability concerns of per user modeling, we propose optimizations that significantly reduce the time to serve recommendations to users. Experiments over actual enterprise data show that more than two orders of speed up is obtained as a result of the proposed methods. 



\end{dissertationabstract}

% This is where the main body of your dissertation goes!
\mainmatter

% Optional Introduction
%\begin{dissertationintroduction}

\chapter{Introduction} 
The past two decades have witnessed a tremendous growth in the amount of data available to users~\cite{edmunds2000problem,ShuhuiAuthor15,IDCDataGrowth,Neilson2011}. Often called information explosion~\cite{van2002information}, this trend is reflected across multiple ecosystems including content sharing systems, social networks and enterprise systems, as well as across different types of the data including videos, images, documents, audio files etc. For example, the total number of images uploaded on Flickr~\cite{Flickr} has risen from 6 billion in 2011 to 10 billion in 2015~\cite{Flickr6B,Flickr10B}. Facebook~\cite{Facebook} stores over 260 billion images and grows at an explosive rate of one billion new photos per week~\cite{beaver2010finding}. In the enterprise ecosystem, unstructured data has been observed to grow annually at a rate of 40-50\%~\cite{IDCDataGrowth}. While the growing size of the available data provides valuable resource to users, its sheer size limits its usability and hence its value. Users face the daunting challenge of obtaining useful or interesting information from the deluge of available data, an issue that is commonly referred to as information overload~\cite{edmunds2000problem}.

\section{Personalization Systems}
In order to assist users navigate the overwhelming amounts of data, there has been a steady increase in the number and popularity of personalization systems that customize the information presented to users~\cite{eirinaki2003web}. These include systems that can provide content recommendations, targeted advertisements, personalized news feeds, suggested connections, preference based query ranking and other forms of personalization. For example, Amazon recommends products to users based on their previously made purchases or viewed products~\cite{Amazon}, Netflix recommends movies accordingly to users' movie watching patterns~\cite{Netflix}, LinkedIn can suggest professional connections based on users' professional social networks and their activities~\cite{LinkedIn}, and Google serves personalized advertisements to users based on their activities on certain websites and their inferred profiles~\cite{Google,castelluccia2012betrayed,GoogleAdsense}. The above are only a few examples of widely used personalization systems that have become household names owing to their popularity. Such systems help users combat information overload by tailoring their experience, and at the same time, enable the content providers and advertisers to understand user interests for better targeting of content, connections, advertisements etc. Indeed the rapid adoption of personalization systems provides compelling evidence to their growing significance~\cite{castellano2009innovations}. 


The growing popularity of personalization systems, combined with the enormous quantitites of data that they operate on and the large number of users that access them, call for design considerations to make such systems scalable. The first scalability consideration is to reduce the manual effort required to deploy and operate personalization systems. Manual involvement can make the process time consuming, less scalable and subjective. In addition, a high efficiency is desired such that the systems can operate on large volumes of data and users while having low time and space requirements. In the next section, we discuss how our research enables personalization systems meet the above considerations. 

\section{Contributions and Overview}


% This calls for ...... 

In this dissertation, we focus on several aspects and variations of personalization systems, and demonstrate the proposed techniques through experiments over different types of the data. The first key contribution of the dissertation addresses automation considerations of personalization systems by focusing on content classification. The second key contribution addresses sparsity of annotations associated with online content such as Flickr images, thus enabling personalization systems leverage the content more effectively and efficiently. The third key contribution addresses efficiency considerations for recommendation systems. Our contributions are summarized below. 

\subsection{Automatically obtaining training data to enable content classification}

In order to customize user experiences based on their inferred interests, personalization systems often build user interest profiles in terms of a set of categories and sub-categories. For example Google Adsense~\cite{GoogleAdsense} collects the sites that have been visited by a user and builds an interest profile from them, as a set of categories and sub-categories. If a user visits a football site several times, Google Adsense may associate the category Sport, or more specifically the sub-category Football with the user. For such systems, the ability to classify content accessed by users into categories (and sub-categories) of interest is crucial. Training classification models to do so requires data that is labeled as per the same set of categories. Since different personalization applications may be interested in different sets of categories, such labeled training data for arbitrary categories is not readily available and manual labeling is typically employed to obtain the same. In this work, we develop a framework that can automate the training data collection and labeling process. 
By leveraging publicly available resources such as Wikipedia~\cite{website:Wikipedia}, our framework selects keywords that can help retrieve training videos. 
Towards this, we define the desired objectives for selection of keywords, and formulate novel optimization methods (LCPD and AAO) to obtain the training data. 
We discuss and evaluate our framework through text based classification of online videos (such as from YouTube~\cite{Youtube}) however our approach is applicable to other forms of data as well. 
Through experiments over real world videos, our framework shows high performance as compared to other methods despite using no manual effort. 

% Add about text based classification? 

\subsection{Addressing sparsity in annotations of online content}

Most web based content sharing systems such as Flickr~\cite{Flickr} allow social tagging that helps assign tags or annotations to content. Since users aren't typically incentivized to annotate content accurately or comprehensively, the content suffers from insufficient and often missing tags, usually referred to as tag sparsity~\cite{SunLang11,MohdSemantic13}. 
As a result, personalization systems face difficulty in recommending such content or in infering user interests based on access to the content. 
%Existing methods employed to address tag sparsity are either limited to using semantic information, or have high space requirements. 
In this work, we show how ontological tag trees can be used to address tag sparsity in an effective and efficient manner. 
We formulate the construction of ontological tag trees as an optimization problem over the set of tags in a corpus, and leverage tag statistics and semantic relationships (from WordNet~\cite{wordnet}) for the construction. The optimization is solved using a novel local search based approach, and experiments on publicly and professionally annotated image corpora show that our approach can achieve as high performance as existing approaches, while offering significant savings in the space requirement. Furthermore, we show how the constructed ontological tag trees can be used to speed up the classification of content. Our work also shows that ontological tag trees are significantly robust to tag noise and variations in tag distributions. 


\subsection{Improving time efficiency of personalized recommendations in enterprises}


In this work, we focus on users accessing data from enterprises repositories. Since enterprise users (knowledge workers) are overwhelmed by the massive growth of the data~\cite{IDGBigDataSurvey14}, we develop a file recommendation system that can efficiently connect users with useful new content. In order to do so, the system models file access patterns for individual users and uses the model to predict if a newly created file would be accessed by the user. Furthermore, we show how the collaboration among users can be leveraged to improve performance without facing the cold start problem. While the evaluations based on actual enterprise data show that our system can recommend content to users with high predictive correctness, the per user modeling raises scalability issues while recommending files to large number of users on a busy repository. In order to address this shortcoming, we develop a novel optimization that can achieve the same predictive correctness while speeding up the recommendation process. We further show that it is possible to obtain several orders of speed up in our system by accepting marginal losses in the model correctness. 


For the above contributions, we have focused on demonstrating our methods by focusing on one data type. However the proposed approaches could potentially be applied to other types of data as well.  

This rest of this dissertation is organized as follows. Chapter 2 describes methods that enable automated content classification by using keywords to obtain training data. Chapter 3 presents approaches to construct and use ontological tag trees and Chapter 4 presents the design of the file recommendation system and how its time efficiency can be improved. Chapter 5 concludes the dissertation and provides suggestions for future research. 


%\end{dissertationintroduction}

\chapter{Methods to Obtain Training Data for Fully Automated Application-Specific Classification}
\input{TrainingData/mainfile.tex}


\chapter{Construction and Evaluation of Ontological Tag Trees}
\input{TagTree/mainfile.tex}


\chapter{Improving Scalability of Personalized Recommendation Systems for Enterprise Knowledge Workers}
\input{FileAccess/mainfile.tex}


\chapter{Conclusion}

Personalization services have seen an significant upsurge in the past two decades, primarily owing to the explosive growth in data available to users, and the proliferation of the Internet. In this dissertation, we identified three automation and efficiency related challenges faced by personalization systems and presented solutions. We summarize these below, along with a few directions of future work. 


Content classifiers are an integral part of most personalization systems. The set of categories into which the content needs to be classified, is typically dictated by the specific personalization application. Traditional approaches for classifier training require significant manual effort to obtain and label the training data, making the overall process labor intensive, non scalable, time consuming and subjective. Thus in Chapter 2, we developed a fully automated framework to select training data given an arbitrary set of categories. We provided a discussion on the desired properties that make a training data lead to high performing classification models. We then proposed two methods that can select keywords to obtain training data with the desired properties. Our methods (LCPD and AAO) offer a very convenient trade-off between tunability and performance. We focus on text based classification of online videos from YouTube. Experiments showed that the proposed framework can successfully obtain training videos in a completely automated manner, and that the resulting classification models can achieve a high performance. As further extensions to this work, it would be interesting to understand the benefit obtained by using different types of modalities to select the training data. For example, for classification of online videos, the trade-off offered by textual, audio and visual features over simply textual features, would be an interesting study. 

The second key challenge we identified was the sparsity of annotations on annotated online content such as Flickr images. Sparse or missing tags inhibit personalization system's ability to recommend content or to infer user interests in terms of tags. In order to address this shortcoming in an effective and a space-efficient manner, in Chapter 3 we defined ontological tag trees and showed how they can be constructed based on corpus statistics and semantic relationships. We formulated the construction of tag trees as an optimization problem solved through a novel local search based approach. We validated the utility of the constructed tag trees over two large image corpora -- one from Flickr, and one from professionally annotated stock images. The evaluation of tag trees was done through two data driven tasks, involving associating images with tags -- one by looking at existing tags, and one without any knowledge of existing tags. We further showed that the proposed approach is robust to tag noise and differences in distributions of the training and test images. The work can be extended in several important directions, for example by constructing directional trees or trees that capture higher degree statistics as obtained from a given corpus. Furthermore, it would be useful to study how tag trees could be used to predict label noise in annotated content or to make content classification more effective. 


Lastly, we studied how file recommendation system could be useful for enterprise users to discover relevant new content. In order to do so, we first designed a system that leverages file metadata to learn per user access models, and uses these models to determine if a newly created file would be relevant to the user or not. We showed how use collaboration could be used to improve the effectiveness of our models, without being affected by the cold start problem like traditional collaborative filtering based recommendation systems. Furthermore, we experimented with real world data and noted scalability limitations of per user modeling based recommendation. In order to address this shortcoming, we proposed a novel optimization that can select user models that may be interested in a given test file. Based on the optimization, we show that the recommendation can be made more than 20 times faster without any loss in the correctness. We also provide a method that can trade-off the model correctness for significant speed up. For example we show that the recommendation can be made more than 169 times for marginal loss in the F-score. In future, it may be useful to study how different dimensionality reduction approaches can improve system efficiency as well as effectiveness. 




% Stuff at the end of the dissertation goes in the back matter
\backmatter
\bibliographystyle{plain} % Or whatever style you want like plainnat
\bibliography{ThesisBib}

\end{document}
