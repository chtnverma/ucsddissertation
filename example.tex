\documentclass[12pt]{ucsddissertation}
% mathptmx is a Times Roman look-alike (don't use the times package)
% It isn't clear if Times is required. The OGS manual lists several
% "standard fonts" but never says they need to be used.
\usepackage{mathptmx}
\usepackage[NoDate]{currvita}
\usepackage{array}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{ragged2e}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{algorithm}% http://ctan.org/pkg/algorithms
\usepackage{amsmath} 
\usepackage{amsthm,amssymb}
%\usepackage[subfigure]{tocloft} 
%\usepackage{subfigure} 
\usepackage{color,caption}
\usepackage[hyphens]{url}
\usepackage[breaklinks=true,pdfborder={0 0 0}]{hyperref}
\usepackage{epsfig} 
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\hilight}[1]{\colorbox{yellow}{#1}}

%% Yahoo -- begin
\newtheorem{definition}{Definition}
\usepackage[mathscr]{euscript}
\usepackage{float}
\usepackage{mathrsfs}
\usepackage{subcaption}
%\usepackage{epstopdf}
\usepackage{soul}
\usepackage{caption}
\renewcommand{\hl}{}
%% Yahoo -- end 


%% Symantec -- begin 
%\usepackage{algorithmic}
\usepackage{xcolor}
\usepackage{url}
\usepackage{pifont}
\usepackage{tabto}
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\codecomment}{\textbackslash \textbackslash}
\DeclareGraphicsExtensions{.eps,.pdf,.png,.jpg}

%% Symantec -- end

\AtBeginDocument{%
	\settowidth\cvlabelwidth{\cvlabelfont 0000--0000}%
}

% OGS recommends increasing the margins slightly.
\increasemargins{.1in}

% These are just for testing/examples, delete them
\usepackage{trace}
%\usepackage{showframe} % This package was just to see page margins
\usepackage[english]{babel}
\newcommand{\comment}[1]{}
\usepackage{blindtext}
\overfullrule5pt
% ---

% Required information
\title{Enabling Automated and Efficient Personalization Systems}
\author{Chetan Kumar Verma}
\degree{Electrical and Computer Engineering (Computer Engineering)}{Doctor of Philosophy}
% Each member of the committee should be listed as Professor Foo Bar.
% If Professor is not the correct title for one, then titles should be
% omitted entirely.
\chair{Professor Sujit Dey}
% Your committee members (other than the chairs) must be in alphabetical order
\committee{Professor David Kriegman}
\committee{Professor Lawrence Saul}
\committee{Professor Truong Nguyen}
\committee{Professor Vikash Gilja}
\degreeyear{2015}

% Start the document
\begin{document}
% Begin with frontmatter and so forth
\frontmatter
\maketitle
\makecopyright
\makesignature
% Optional
\begin{dedication}
\setsinglespacing
\raggedright % It would be better to use \RaggedRight from ragged2e
\parindent0pt\parskip\baselineskip
\centering
To mom and dad 
\end{dedication}
% Optional
\comment{
\begin{epigraph}
\vskip0pt plus.5fil
\setsinglespacing
{\flushright
True ease in writing comes from art, not chance,\\
As those move easiest who have learn'd to dance.\\
'T is not enough to no harshness gives offence,---\\
The sound must seem an echo to the sense.

\vskip\baselineskip
\textit{Alexander Pope}\par}
\vfil
\begin{center}
You write with ease to show your breeding,\\
But easy writing's curst hard reading.

\vskip\baselineskip
\textit{Richard Brinsley Sheridan}
\end{center}
\vfil
\noindent Writing, at its best, is a lonely life. Organizations for
writers palliate the writer's loneliness, but I doubt if they improve
his writing. He grows in public stature as he sheds his loneliness and
often his work deteriorates. For he does his work alone and if he is a
good enough writer he must face eternity, or the lack of it, each day.

\vskip\baselineskip
\hskip0pt plus1fil\textit{Ernest Hemingway}\hskip0pt plus4fil\null

\vfil
\end{epigraph}
}

% Next comes the table of contents, list of figures, list of tables,
% etc. If you have code listings, you can use \listoflistings (or
% \lstlistoflistings) to have it be produced here as well. Same with
% \listofalgorithms.
\tableofcontents
\listoffigures
\listoftables

% Preface
\comment{
\begin{preface}
Almost nothing is said in the manual about the preface. There is no
indication about how it is to be typeset. Given that, one is forced to
simply typeset it and hope it is accepted. It is, however, optional
and may be omitted.
\end{preface}
}

% Your fancy acks here. Keep in mind you need to ack each paper you
% use. See the examples here. In addition, each chapter ack needs to
% be repeated at the end of the relevant chapter.
\begin{acknowledgements}


This dissertation would not have been possible without the help and support of my family, friends, colleagues and mentors. I would like to take this opportunity to thank them. 


First, I would like to thank Prof. Sujit Dey for patience to train me to think and write with clarity. This has helped me not only in my research and technical writing, but also in other aspects of my life. 

My parents have been the cornerstone of my education and career through their unconditional and selfless support. I would like to thank them for being extremely patient even though they didnâ€™t always understand my opinions and decisions. This achievement is as much mine as it is theirs. 

I would also like to thank Sandeep Bhatkar, Michael Hart, Vijay Mahadevan, Nikhil Rasiwasia, Gaurav Aggarwal for mentoring me during internships. My internships have facilitated a good chunk of my learning and the contribution of my mentors has been significant. I would like to thank Nitesh Shroff for doubling up as a friend and mentor when I needed the help. 

Graduate school has been a fun and learning experience for me. I would like to thank my friends Kritika, Bharathan, Rishi, Manish, Ravee, Sumit, and many others for making the journey enjoyable. It would have been much less exciting if I did not have them to pour my heart out. My labmates especially Yao, Jason, Po-Han, Ranjini, Ali have also been helpful in keeping my sanity over the past six years.  

Lastly, I would also like to thank my friends from IIT Madras. They have been my constant support and have somehow been able to understand what I have intended to say. 

Chapter 2, in full, is a reprint of the material as it appears in
Numerical Grid Generational in Computational Fluid Mechanics~2009.
Smith, Laura; Smith, Jane~D., Pineridge Press,~2009. The dissertation
author was the primary investigator and author of this paper.

Chapter 3, in part, has been submitted for publication of the material
as it may appear in Education Mechanics,~2009, Smith, Laura; Smith,
Jane~D., Trailor Press,~2009. The dissertation author was the primary
investigator and author of this paper.

Chapter 5, in part is currently being prepared for submission for
publication of the material. Smith, Laura; Smith, Jane~D\@. The
dissertation author was the primary investigator and author of this
material.
\end{acknowledgements}

% Stupid vita goes next
\begin{vita}
\noindent
\begin{cv}{}
\begin{cvlist}{}
\item[2008] Bachelor of Technology, \\Electrical Enginering, \\Indian Institute of Technology, Madras 
\item[2011] Master of Science, \\Electrical and Computer Engineering(Computer Engineering), \\University of California, San Diego 
\item[2010--2015] Graduate Student Researcher, \\Mobile Systems Design Lab, \\Department of Electrical and Computer Engineering, \\University of California, San Diego
\item[2011--2015]  Doctor of Philosophy, \\Department of Electrical and Computer Engineering, \\University of California, San Diego
\end{cvlist}
\end{cv}

% This puts in the PUBLICATIONS header. Note that it appears inside
% the vita environment. It is optional.
\publications
{\justify
\noindent\textbf{Journals} \\ \\
\noindent \textbf{C. Verma}, S. Dey, ``Methods to Obtain Training Videos for Fully Automated Application-Specific Classification'', IEEE Access, vol. 3, pp 1188-1205, 2015. \\

\noindent \textbf{C. Verma}, V. Mahadevan, N. Rasiwasia, G. Aggarwal, R. Kant, A. Jaimes, S. Dey, ``Construction and Evaluation of Ontological Tag Trees'', Elsevier Expert Systems and Applications, vol. 42 (24), pp 9587-9602, 2015. \\

\noindent \textbf{C. Verma}, M. Hart, S. Bhatkar, A. Parker-Wood, S. Dey, ``Improving Scalability of Personalized Recommendation Systems for Enterprise Knowledge Workers'', Under review. \\

\noindent \textbf{C. Verma}, B. R. Tamma, B. S. Manoj, R. Rao, ``A Realistic Small-World Model for Wireless Mesh Networks'', IEEE Communication Letters, vol. 15 (4), pp 455-457, 2011. \\

\noindent\textbf{Conferences} \\ \\
\noindent \textbf{C. Verma}, M. Hart, S. Bhatkar, A. Parker-Wood, S. Dey, ``Access Prediction for Knowledge Workers in Enterprise Data Repositories'', International Conference on Enterprise Information Systems (ICEIS), 2015. [\textbf{Nominated for best student paper award}] \\

\noindent B. Balaji, \textbf{C. Verma}, B. Narayanaswamy, Y. Agarwal, ``Zodiac: Organizing Large Deployment of Sensors to Create Reusable Applications for HVAC Management'', ACM International Conference on Embedded Systems For Energy-Efficient Built Environments (BuildSys), 2015. \\

\noindent \textbf{C. Verma}, V. Mahadevan, N. Rasiwasia, G. Aggarwal, R. Kant, A. Jaimes, S. Dey, ``Construction of Tag Ontological Graphs by Locally Minimizing Weighted Average Hops'', ACM World Wide Web (WWW poster), 2014. \\ 


\noindent \textbf{C. Verma}, S. Dey, ``Fully Automated Learning for Application-Specific Web Video Classification'', IEEE/WIC/ACM International Conference on Web Intelligence (WI), 2013. \\ 

\noindent A. Verma, \textbf{C. Verma}, B. R. Tamma, B. S. Manoj, R. Rao, ``New Link Addition Strategies for Multi-Gateway Small World Wireless Mesh Networks'', IEEE Advanced Networks and  Telecommunication Systems (ANTS), 2010. 

}

\comment{

% This puts in the FIELDS OF STUDY. Also inside vita and also
% optional.
\fieldsofstudy
\noindent Major Field: Engineering (Specialization or Focused Studies)
\vskip\baselineskip
Studies in Applied Mathematics\par
Professors Alpha Beta and Gamma Delta
\vskip\baselineskip
Studies in Mechanices\par
Professors Epsilon Zeta and Eta Theta
\vskip\baselineskip
Studies in Electromagnetism\par
Professors Iota Kappa and Lambda Mu

}
\end{vita}

% Put your maximum 350 word abstract here.
\begin{dissertationabstract}

The growth of Internet 

The past two decades have witnessed a spurge in personalization services that have the goal of connecting content consumers 

data available to consumers, making data retrieval, organization and recommendation increasingly important. In almost the same period, personalization services have 

The Abstract begins here. The abstract is limited to 350 words for a
doctoral dissertation. It should consist of a short statement of the
problem, a brief explanation of the methods and procedures employed in
generating the data, and a condensed summary of the findings of the
study. The abstract may continute onto a second page if necessary. The
text of the abstract must be double spaced.
\end{dissertationabstract}

% This is where the main body of your dissertation goes!
\mainmatter

% Optional Introduction
%\begin{dissertationintroduction}

\chapter{Introduction} 
The past two decades have witnessed a tremendous growth in the amount of data available to users~\cite{edmunds2000problem,ShuhuiAuthor15,IDCDataGrowth,Neilson2011}. Often called ``Information explosion''~\cite{van2002information}, this trend is reflected across multiple ecosystems including Web-based sharing systems, social networks and enterprise systems, as well as across different types of the data including videos, images, documents, audio files, tweets etc. For example, the total number of images uploaded on Flickr~\cite{Flickr} has risen from 6 billion in 2011 to 10 billion in 2015~\cite{Flickr6B,Flickr10B}. Facebook~\cite{Facebook} stores over 260 billion images and grows at an explosive rate of one billion new photos per week~\cite{beaver2010finding}. In the enterprise ecosystem, unstructured data has been observed to grow annually at a rate of 40-50\%~\cite{IDCDataGrowth}. While the growing size of the available data provides valuable resource to users, its sheer size limits its usability and hence its value. Users face the daunting challenge of obtaining useful or interesting information from the deluge of available data, an issue that is commonly referred to as Information Overload~\cite{edmunds2000problem}.

\section{Personalization Systems}
In order to assist users navigate the overwhelming amounts of data, there has been a steady increase in the number and popularity of personalization systems that customize the information presented to users~\cite{eirinaki2003web}. These include systems that can provide content recommendations, targetted advertisements, personalized news feed, connection recommendations, preference based query personalization and other forms of personalization. For example Amazon recommends products to users based on their previously made purchases or viewed products~\cite{Amazon}. Netflix recommends movies accordingly to users' movie watching patterns~\cite{Netflix}. LinkedIn can suggest professional connections based on the users' professional social networks and their activities~\cite{LinkedIn}. Google serves personalized advertisements to users based on their activities on certain websites and their inferred profiles~\cite{Google,castelluccia2012betrayed,GoogleAdsense}. The above are only a few examples of widely used personalization systems that have become household names owing to their popularity. Such systems help users combat information overload by tailoring their experience, and at the same time, enable the content providers and advertisers to understand user interests for better targetting of content, connections, advertisements etc. Indeed the rapid adoption of personalization systems provides compelling evidence to their growing significance~\cite{castellano2009innovations}. 


The growing popularity of personalization systems, combined with the enormous quantitites of data that they operate on and the large number of users that access them call for design considerations to make such systems scalable. The first scalability consideration is to reduce the manual effort required to produce and operate personalization systems. Manual involvement can make the process time consuming, less scalable and subjective. In addition, a high efficiency is desired such that the systems can operate on large volumes of data and users using less time and space resources. In the next section, we discuss how our research enables personalization systems meet the above considerations. 

\section{Contributions and Overview}

In order to customize the user experience based on their inferred interests, personalization systems often build user interest profiles in terms of a set of categories and sub-categories. For example Google Adsense~\cite{GoogleAdsense} collects the sites that have been visited by a user and builds an interest profile from them, as a set of categories and sub-categories. If a user visits a football site several times, \cite{GoogleAdsense} may associate the category Sport, or more specifically the sub-category Football with the user. For such systems, the ability to classify content accessed by users into the same set of categories (and sub-categories) is crucial. 
% This calls for ...... 

In this dissertation, we focus on different components of personalization systems, and demonstrate the proposed techniques through experiments over different types of the data. The first key contribution of the dissertation addresses automation considerations of personalization systems by focusing on content classification. The second key contribution addresses sparsity of annotations with online content such as Flickr images, thereby enabling personalization systems leverage the content more effectively. The third key contribution addresses efficiency considerations of recommendation systems. Our contributions are summarized below. 

\subsection{Automatically obtaining data to train classification models}

As mentioned above, classification techniques are crucial for personalization systems. Traditional supervised classification techniques require data that is labeled as per the categories of interest, to train classification models. Since different personalization applications may be interested in different sets of categories, such training data for arbitrary categories is not readily available. Manual labeling is typically employed to obtain the training data. In this work, we focus on automating the training data collection process. We demonstrate our techniques for online videos (such as from YouTube~\cite{YouTube}) however the techniques are applicable to other modalities of data as well. By leveraging publicly available textual resources such as Wikipedia~\cite{website:Wikipedia}, we select keywords that can help retrieve training videos. Towards this, we define the desired objectives for selection of keywords, and formulate novel optimization methods (LCPD and AAO) to obtain the training videos. Through experiments over real world videos form YouTube, our method shows significant improvement over other methods despite using zero manual effort. 

% Add about text based classification? 

\subsection{Addressing tag sparsity for annotated online content}

Annotated content such as Flickr~\cite{Flickr} images suffers from the problem of insufficient and often missing tags, usually referred to as tag sparsity~\cite{SunLang11,MohdSemantic13}. 
As a result, personalization systems face difficulty in recommending such content or in infering user interests by accesing the content. Existing methods employed to address tag sparsity are either limited to using semantic information, or have high space requirements. Thus, we show how ontological tag trees can be used to encode information present in a given corpus pertaining to interaction between the tags, in a space efficient manner. We show that the performance of our method matches that of existing systems while offering significant savings in the space requirement. We formulate the construction of ontological tag trees as an optimization problem over the set of tags in a corpus, and leverage tag statistics and semantic relationships (from WordNet~\cite{wordnet}). The optimization is solved using a novel local search based approach, and experiments are shown over different types of image corpora. Furthermore, we also show how the constructed ontological tag trees can be used to speed up the classification of content. 


\subsection{Improving time efficiency of personalized recommendations in enterprises}


In this work, we focus on knowledge workers accessing data from enterprises repositories. Since enterprise users (knowledge workers) are overwhelmed by the massive growth of the data~\cite{IDGBigDataSurvey14}, we develop a file recommendation system that can efficiently connect users with useful new content. In order to do so, the system models file access patterns for individual users and uses the model to predict if a newly created file would be accessed by the user. Furthermore, we show how the collaboration among users can be leveraged to improve performance without facing the cold start problem. While the evaluations based on actual enterprise data show that our system can recommend content to users with high predictive correctness, the per user modeling raises scalability issues while recommending files to large number of users on a busy repository. In order to address this shortcoming, we develop a novel optimization that can achieve the same predictive correctness while speeding up the recommendation process. We further show that it is possible to obtain several orders of speed up in our system by accepting marginal losses in the model correctness. 


For the above contributions, we have focused on demonstrating our methods by focusing on one data type. However the proposed approaches could potentially be applied to other types of data as well.  

This rest of this dissertation is organized as follows. Chapter 1 describes methods that enable automated content classification by using keywords to obtain training data. Chapter 2 presents approaches to construct and use ontological tag trees and Chapter 3 presents the design of the file recommendation system and how its time efficiency can be improved. Chapter 4 concludes the dissertation and provides directions for future research. 


%\end{dissertationintroduction}

\chapter{Methods to Obtain Training Data for Fully Automated Application-Specific Classification}
\input{TrainingData/mainfile.tex}


\chapter{Construction and Evaluation of Ontological Tag Trees}
\input{TagTree/mainfile.tex}


\chapter{Improving Scalability of Personalized Recommendation Systems for Enterprise Knowledge Workers}
\input{FileAccess/mainfile.tex}


% Stuff at the end of the dissertation goes in the back matter
\backmatter
\bibliographystyle{plain} % Or whatever style you want like plainnat
\bibliography{ThesisBib}

\end{document}
